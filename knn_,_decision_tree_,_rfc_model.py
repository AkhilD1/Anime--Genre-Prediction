# -*- coding: utf-8 -*-
"""KNN , Decision Tree , RFC Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nLGFFmG_T_sqnQJhhRYtBfxKvG1_1Cdb

# Importing Modules
"""

import pandas as pd
import io
import numpy as np
import matplotlib.pyplot as plt
import pickle
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
from scipy.stats.stats import pearsonr
from scipy import stats
from numpy import array
from numpy import percentile
from sklearn.naive_bayes import BernoulliNB
import re
from sklearn import preprocessing
from sklearn.preprocessing import PolynomialFeatures
#To eliminate Warning Messages
import warnings
warnings.filterwarnings('ignore')
from sklearn.metrics import accuracy_score
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import GridSearchCV

import joblib
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.svm import LinearSVC
from sklearn.metrics import classification_report

"""## Upgrading Version of Pandas to match with version of pickle"""

pip install --upgrade pandas==1.3.4

"""## Loading Data for training"""

from sklearn.metrics import classification_report
import pickle


with open('/content/drive/MyDrive/dataset/tfidf_document_matrix.obj', 'rb') as f:
    x = pickle.load(f)
with open('/content/drive/MyDrive/dataset/labels.obj', 'rb') as f:
    y = pickle.load(f)

"""## Splitting the data into test and train"""

x_train, x_test, y_train, y_test = train_test_split(x,y, random_state=0, test_size=0.3, shuffle=True)
print('Shape of training data', x_train.shape)
print('Shape of training labels', y_train.shape)
print('Shape of test data', x_test.shape)
print('Shape of test labels', y_test.shape)

from numpy import ndarray

"""# Building a Decision Tree Classifier Model"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

"""# Decision Tree"""

from sklearn.tree import DecisionTreeClassifier
clf_model = DecisionTreeClassifier(criterion="gini", random_state=42,max_depth=3, min_samples_leaf=5)   
clf_model.fit(x_train,y_train)

y_predict = clf_model.predict(x_test)

from sklearn.metrics import accuracy_score
accuracy_score(y_test,y_predict)

"""# Build a random forest classifier model without

# RFC
"""

clf = RandomForestClassifier(max_depth=1500, random_state=42)
clf.fit(x_train, y_train)

y_pred = clf.predict(x_test)

print("ACCURACY OF THE MODEL: ", accuracy_score(y_test, y_pred))

"""## Implementing a K-Nearest Neighbours model

# KNN model
"""

neigh = KNeighborsClassifier(n_neighbors=3)
neigh.fit(x_train, y_train)

y_pred = neigh.predict(x_test)

print("ACCURACY OF THE KNN MODEL is: ", accuracy_score(y_test, y_pred))

"""# Grid Search CV"""

from sklearn.neighbors import KNeighborsClassifier

from sklearn.pipeline import Pipeline

from sklearn.ensemble import RandomForestClassifier

# Create first pipeline for base without reducing features.
from sklearn.linear_model import LogisticRegression
pipe = Pipeline([('classifier' , RandomForestClassifier())])
# pipe = Pipeline([('classifier', RandomForestClassifier())])

# Create param grid.

param_grid = [
    {'classifier' : [LogisticRegression()],
     'classifier__penalty' : ['l1', 'l2'],
    'classifier__C' : np.logspace(-4, 4, 20),
    'classifier__solver' : ['liblinear']},
    {'classifier' : [RandomForestClassifier()],
    'classifier__n_estimators' : list(range(10,101,10)),
    'classifier__max_features' : list(range(6,32,5)),}
]

# Create grid search object

clf = GridSearchCV(pipe, param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1)

# Fit on data

best_clf = clf.fit(x_train, y_train)

clf.best_params_

clf = RandomForestClassifier(max_depth=500, max_features=31, n_estimators=10, random_state=157)
clf.fit(x_train, y_train)

y_pred = clf.predict(x_test)

print("ACCURACY OF THE MODEL: ", accuracy_score(y_test, y_pred))